DRAINTASKER - clears filling disks
================================================================

full documentation on the Draintasker wiki:
https://webarchive.jira.com/wiki/display/WEBOPS/Draintasker

  1) if there are draintasker procs, kill them.
  2) if files in the way, investigate and move aside, 
     eg mv LAUNCH.open LAUNCH.1, mv ERROR ERROR.1
        good to number each failure/error file
  3) check the status of your disks
     ./get-status.sh
  4) (optional) test petabox-to-thumper path on single series
     ./launch-transfers.sh
  5) log into home and open a screen session
  6) in screen, ssh crawler, cd /0/crawling/draintasker/
  7) run dtmon.sh to continuously drain each job+disk
     ./dtmon.sh

DRAIN DAEMON
  dtmon.sh                   run drain-job periodically
  drain-job.sh               run draintasker processes in single mode

DRAIN PROCESSING
  delete-verified-warcs.sh   delete original (verified) w/arcs from
                             each series 
  get-remote-warc-urls.sh    report remote md5 and url for all
                             filesxml in series 
  item-submit-task.sh        submit catalog task for series
  item-verify-download.sh    wget remote w/arc and verify checksum for
                             series 
  item-verify-size.sh        verify remote size of w/arc series
  launch-transfers.sh        submit transfer tasks for series
  make-manifests.sh          compute md5s into series MANIFEST
  pack-warcs.sh              create warc series when available
  task-check-success.sh      check and report task success by task_id
  verify-transfers.sh        run task-check-success and item-verify
                             for series 

UTILS
  addup-warcs.sh             report count and total size of warcs
  bundle-crawl-artifacts.sh  make tarball of crawldata for permanent
                             storage 
  check-crawldata-staged.sh  report staged crawldata file count+size
  check-crawldata.sh         report source crawldata file count+size
  copy-crawldata.sh          copy all crawldata preserving dir
                             structure 
  get-status.sh              report daemons, prerequisites and disk
                             usage 
  make-and-store-bundle.sh   make bundles and scp to staging

CONFIG

  job_dir       /{crawldata}/{job_name}
  xfer_job_dir  /{rsync_path}/{job_name}
  warc_series   {xfer_job_dir}/{warc_series}

  + add [incoming_3] rule to /etc/rsyncd.conf
  + ensure user petabox user exists: /home-local/petabox
  + get petabox authorized_keys from "draintasking" crawler
    @crawling08:~$ scp /home-local/petabox/.ssh/authorized_keys\
    root@ia400131:/home-local/petabox/.ssh/authorized_keys

PREREQUISITES

  DRAINME      {job_dir}/DRAINME
  FINISH_DRAIN {job_dir}/FINISH_DRAIN

  PACKED    {warc_series}/PACKED
  MANIFEST  {warc_series}/MANIFEST
  LAUNCH    {warc_series}/LAUNCH
  TASK      {warc_series}/TASK
  TOMBSTONE {warc_series}/TOMBSTONE

PROCESSING 

  monitor job and drain (with dtmon.sh) - while DRAINME file exists,
  pack warcs (PACKED), make manifests (MANIFEST), launch transfers
  (TASK), verify transfers (TOMBSTONE), and finally, delete verified
  warcs, then sleep for sleep_time seconds before trying again.

    dtmon.sh job_dir xfer_job_dir thumper
      drain-job job_dir xfer_job_dir thumper
        pack-warcs.sh       => PACKED
        make-manifests.sh   => MANIFEST
        launch-transfers.sh => LAUNCH, TASK
        verify-transfers.sh => SUCCESS, TOMBSTONE
        delete-verified-warcs.sh

STATUS

  get-status.sh crawldata_dir xfer_dir

THUMPER

  the target thumper is reported periodically by petabox ops,
  and the latest transfers (viewable through catalog) indicate
  the current/lastest target hostname:

    [to_server] => ia500408.us.archive.org 

  http://home.us.archive.org/catalog.php?\
    search_identifier=move_to_thumper_WS_*&history=1 


----
siznax 2010
